# 1. 通用设计方法

* 使用缓存提升性能
* 异步处理 
  * 消息队列等
* 组成分布式集群（通过分层的方式进行横向扩展）

# 2. 架构分层

在系统从0到1的阶段，为了让系统快速上线，我们通常是不考虑分层的。但是随着业务越来越复杂，大量的代码纠缠在一起，会出现逻辑不清晰、各模块相互依赖、代码扩展性差、改动一处就牵一发而动全身等问题。

* 分层优点
  * 分层可以简化系统设计，让不同的人专注做某一层次的事情（类比网络的七层）
  * 分层可以做到很高的复用
  * 分层可以更容易进行横向扩展
* 缺点
  * 增加代码的复杂度（比如一个简单的查库请求，分层的话，你需要一层一层的调用）
  * 如果不同层次独立部署，层次间通过网络来交互，那么就会有性能损耗

# 3.系统设计目标

## 3.1 高性能

* 性能的度量指标

  * 平均值（参考）
  * 最大值
  * 分位值（主要使用）

  >   分位值有很多种，比如90分位、95分位、75分位。以90分位为例，我们把这段时间请求的响应时间从小到大排序，假如一共有100个请求，那么排在第90位的响应时间就是90分位值。分位值排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况，分位值越大，对于慢请求的影响就越敏感。

* 优化方式

  * 提高系统的处理核心数

    > 在并发压力小的时候，增加处理核心数会显著提高吞吐量，当并发压力大时，再一味的增加处理核心数，便会因为并行的任务对资源的争抢也会愈发严重。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是性能测试中的拐点模型。

  * 减少单次任务的相应时间

    * CPU密集型 （采取更高效率的算法）

    * IO密集型  （具体瓶颈具体分析）

      > IO密集型系统指的是系统的大部分操作是在等待IO完成，这里IO指的是磁盘IO和网络IO。我们熟知的系统大部分都属于IO密集型，比如数据库系统、缓存系统、Web系统。这类系统的性能瓶颈可能出在系统内部，也可能是依赖的其他系统

## 3.2 高可用

**可用性的度量**

* 平均故障间隔的意思
* 故障的平均恢复时间

**高可用系统设计的思路**

* 系统设计

  * 故障转移

    * 对等节点（比如nginx流量分发，一个节点故障就发到另一个节点）

    * 不对等节点（主备）

      > 故障检测：心跳
      >
      > 选主节点：选主的结果需要在多个备份节点上达成一致，所以会使用某一种分布式一致性算法，比如Paxos，Raft

  * 超时控制

    > 超时时间短了，会造成大量的超时错误，对用户体验产生影响；
    >
    > 超时如果过长，调用方就会阻塞在这次调用上，它已经占用的资源得不到释放。当存在大量这种阻塞请求时，调用方就会因为用尽资源而挂掉；
    >
    > 超时控制实际上就是不让请求一直保持，而是在经过一定时间之后让请求失败，释放资源给接下来的请求使用，这对于用户来说是有损的，但是却是必要的，因为它牺牲了少量的请求却保证了整体系统的可用性。

  * 降级

    > **保证核心服务的稳定而牺牲非核心服务的做法**，暂时停用不必要的服务

  * 限流

    > 通过对并发的请求进行限速来保护系统
    >
    > 比如对于Web应用，我限制单机只能处理每秒1000次的请求，超过的部分直接返回错误给客户端。虽然这种做法损害了用户的使用体验，但是它是在极端并发下的无奈之举，是短暂的行为，因此是可以接受的。

* 系统运维

  * 灰度发布
  * 故障演练

## 3.3 可扩展

扩展的时候应该多考虑瓶颈处

一般无状态的服务和组件更易于扩展，而像MySQL这种存储服务是有状态的，就比较难以扩展。因为向存储集群中增加或者减少机器时，会涉及大量数据的迁移，而一般传统的关系型数据库都不支持。这就是为什么提升系统扩展性会很复杂的主要原因

* 存储层的扩展性（分库分表）
* 业务层的扩展性（各个业务依赖自己独有的数据库资源）

# 4. 池化技术

核心思想就是空间换时间

期望使用预先创建好的对象来减少频繁创建对象的性能开销，同时还可以对对象进行统一的管理，降低了对象的使用的成本

> - 池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。
> - 池子中的对象需要在使用之前预先初始化完成，这叫做池子的**预热**，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。
> - 池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题



## 4.1 连接池

> 比如用连接池预先建立数据库连接，来保证数据库连接复用，不然每次执行sql语句都要进行连接建立和销毁，那就太影响性能了，执行一条sql的时间：连接建立销毁的时间=1:4 
>
> 注意问题：
>
> * 数据库的域名对应的IP发生了变更，池子的连接还是使用旧的IP，当旧的IP下的数据库服务关闭后，再使用这个连接查询就会发生错误；
>
> * MySQL有个参数是“wait_timeout”，控制着当数据库连接闲置多长时间后，数据库会主动地关闭这条连接。这个机制对于数据库使用方是无感知的，所以当我们使用这个被关闭的连接时就会发生错误
>
> 解决：
>
> * 启动一个线程来定期检测连接池中的连接是否可用，比如使用连接发送“select 1”的命令给数据库看是否会抛出异常，如果抛出异常则将这个连接从连接池中移除，并且尝试关闭。目前C3P0连接池可以采用这种方式来检测连接是否可用，**也是我比较推荐的方式**
> * 2.在获取到连接之后，先校验连接是否可用，如果可用才会执行SQL语句。比如DBCP连接池的testOnBorrow配置项，就是控制是否开启这个验证。这种方式在获取连接时会引入多余的开销，**在线上系统中还是尽量不要开启，在测试服务上可以使用。**

## 4.2 线程池

> 如果你使用线程池请**一定记住不要使用无界队列**（即没有设置固定大小的队列）。也许你会觉得使用了无界队列后，任务就永远不会被丢弃，只要任务对实时性要求不高，反正早晚有消费完的一天。但是，大量的任务堆积会占用大量的内存空间，一旦内存空间被占满就会频繁地触发Full GC，造成服务不可用，我之前排查过的一次GC引起的宕机，起因就是系统中的一个线程池使用了无界队列。

# 5. 数据库优化

当我们面临高并发的查询数据请求时，可以使用主从读写分离的方式，部署多个从库分摊读压力；当存储的数据量达到瓶颈时，我们可以将数据分片存储在多个节点上，降低单个存储节点的存储压力

## 5.1 主从读写分离

**主从读写分离有两个技术上的关键点：**

> 1. 一个是数据的拷贝，我们称为主从复制；
> 2. 在主从分离的情况下，我们如何屏蔽主从分离带来的访问数据库方式的变化，让开发同学像是在使用单一数据库一样。

* **主从复制**

> 做了主从复制之后，我们就可以在写入时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响到读请求的执行。同时呢，在读流量比较大的情况下，我们可以部署多个从库共同承担读流量；
>
> 另外，从库也可以当成一个备库来使用，以避免主库故障导致数据丢失。

**是不是我无限制地增加从库的数量就可以抵抗大量的并发呢？**实际上并不是的。因为随着从库数量增加，从库连接上来的IO线程比较多，主库也需要创建同样多的log dump线程来处理复制的请求，对于主库资源消耗比较高，同时受限于主库的网络带宽，所以在实际使用中，一般一个主库最多挂3～5个从库。



**还会产生主从延迟导致的不能及时读的问题？**

举个例子：

> 在发微博的过程中会有些同步的操作，像是更新数据库的操作，也有一些异步的操作，比如说将微博的信息同步给审核系统，所以我们在更新完主库之后，会将微博的ID写入消息队列，再由队列处理机依据ID在从库中获取微博信息再发送给审核系统。此时如果主从数据库存在延迟，会导致在从库中获取不到微博信息，整个流程会出现异常
>
> 
>
> 解决方案：
>
> * **第一种方案是数据的冗余。**你可以在发送消息队列时不仅仅发送微博ID，而是发送队列处理机需要的所有微博信息，借此避免从数据库中重新查询数据。（**优先考虑**，方式足够简单，不过可能造成单条消息比较大，从而增加了消息发送的带宽和时间。）
> * **第二种方案是使用缓存。**我可以在同步写数据库的同时，也把微博的数据写入到redis缓存里面，这样队列处理机在获取微博信息的时候会优先查询缓存，这样也可以保证数据的一致性。（**先更新数据库再更新缓存**）
> * **最后一种方案是查询主库。**我可以在队列处理机中不查询从库而改为查询主库。不过，这种方式使用起来要慎重，要明确查询的量级不会很大，是在主库的可承受范围之内，否则会对主库造成比较大的压力。（**不推荐**，主库压力大）



* **访问数据库**

> * 一类是以代码形式内嵌运行在应用程序内部。你可以把它看成是一种数据源的代理，它的配置管理着多个数据源，每个数据源对应一个数据库，可能是主库，可能是从库。当有一个数据库请求时，中间件将SQL语句发给某一个指定的数据源来处理，然后将处理结果返回。
>
>   > 这一类中间件的优点是简单易用，没有多余的部署成本，因为它是植入到应用程序内部，与应用程序一同运行的，所以比较适合运维能力较弱的小团队使用；缺点是缺乏多语言的支持，目前业界这一类的主流方案除了TDDL，还有早期的网易DDB，它们都是Java语言开发的，无法支持其他的语言。另外，版本升级也依赖使用方更新，比较困难。
>
> * 另一类是单独部署的代理层方案，这一类中间件部署在独立的服务器上，业务代码如同在使用单一数据库一样使用它，实际上它内部管理着很多的数据源，当有数据库请求时，它会对SQL语句做必要的改写，然后发往指定的数据源
>
>   > 它一般使用标准的MySQL通信协议，所以可以很好地支持多语言。由于它是独立部署的，所以也比较方便进行维护升级，比较适合有一定运维能力的大中型团队使用。它的缺陷是所有的SQL语句都需要跨两次网络：从应用到代理层和从代理层到数据源，所以在性能上会有一些损耗。

## 5.2 分库分表

为什么要使用分库分表？

> * 随着系统的发展，单个表的数据量超过了千万甚至到了亿级别。这时即使你使用了索引，索引占用的空间也随着数据量的增长而增大，数据库就无法缓存全量的索引信息，那么就需要从磁盘上读取索引数据，就会影响到查询的性能了
> * 数据量的增加也占据了磁盘的空间，数据库在备份和恢复的时间变长
> * 不同模块的数据，比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块都会受到影响
> * 随着系统写入请求量的增长，数据库系统需要处理更高的并发写入请求



* 垂直拆分

> **垂直拆分就是将数据库的表拆分到多个不同的数据库中**
>
> 垂直拆分的原则一般是按照业务类型来拆分，核心思想是专库专用



**数据库垂直拆分后依然不能解决某一个业务模块的数据大量膨胀的问题，这时候就要对数据库进行水平拆分了**

**和垂直拆分的关注点不同，垂直拆分的关注点在于业务相关性，而水平拆分指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点。**

拆分规则

* 按照某一个字段的哈希值进行拆分，比如用户表（先哈希到库，再哈希到库中的具体的表）
* 按照某一个字段的区间进行拆分，比如订单表，可以一个月一个表（但要提前建好表，不然没表可以拆入导致出错）



分库分表带来的问题

> * **引入了分区键（分库分表键）**
>
> > ​        因为我们之后所有的查询都需要带上这个字段，才能找到数据所在的库和表，否则就只能向所有的数据库和数据表发送查询命令
> >
> > ​      **解决方案：**
> >
> > ​       假如我们使用自增id主键作为分区键，假如当我们需要按照姓名查询用户时，我们不可能再按姓名做一次拆分，而是可以建立一个姓名和ID的映射表，在查询的时候要先通过姓名查询到ID，再通过ID查询完整的数据，这个表也可以是分库分表的，也需要占用一定的存储空间，但是因为表中只有两个字段，所以相比重新做一次拆分还是会节省不少的空间的
>
> 
>
> * **一些数据库的特性在实现时可能变得很困难**
>
> > * 难以使用join语句
> >
> > ​       在多库就无法再使用join了，不过一般情况下使用join的情况不多，即使有也一般是把两个表的数据取出后在业务代码里面做筛选，复杂是有一些，不过是可以实现的
> >
> > * 如何查询数据总数
> >
> > ​       可以将计数的数据单独存储在一张表中或者记录在Redis里面。

补充：

> * 如果在性能上没有瓶颈点那么就尽量不做分库分表；
> * 如果要做，就尽量一次到位，比如说16库，每个库64表就基本能够满足几年内你的业务的需求（数据迁移麻烦）



# 6. 分布式id

自增id在分库分表后就不能保证id的全局唯一性了

**为什么不使用uuid作为数据库主键？**

> * 生成的ID最好具有单调递增性，也就是有序的，而UUID不具备这个特点，**因为在系统设计时，ID有可能成为排序的字段**
> * **ID有序也会提升数据的写入性能**，因为InnoDB存储引擎使用B+树存储索引数据，避免页分裂导致的数据迁移，并且顺序写就不需要寻道，会大大提升索引的写入性能。
> * **UUID不能作为ID的另一个原因是它不具备业务含义**，而如果生成的ID可以被反解，那么从反解出来的信息中我们可以对ID来做验证，我们可以从中知道这个ID的生成时间，从哪个机房的发号器中生成的，为哪个业务服务的，对于问题的排查有一定的帮助。
> * UUID是由32个16进制数字组成的字符串，如果作为数据库主键使用比较耗费空间。



* 雪花算法

| 首位废弃 | 41位时间戳                                    | 机房码+机器码（10位） | 12位序列号    |
| -------- | --------------------------------------------- | --------------------- | ------------- |
| 0        | 0000011 00001100 01010000 11001010 00110000 0 | 1111111111            | 00000000 0000 |

算法的两种实现方式

> * **一种是嵌入到业务代码里，也就是分布在业务服务器中。**这种方案的好处是业务代码在使用的时候不需要跨网络调用，性能上会好一些，但是就需要更多的机器ID位数来支持更多的业务服务器。另外，由于业务服务器的数量很多，我们很难保证机器ID的唯一性，所以就需要引入ZooKeeper等分布式一致性组件来保证每次机器重启时都能获得唯一的机器ID。
>
> * **另外一个部署方式是作为独立的服务部署，这也就是我们常说的发号器服务。**业务在使用发号器的时候就需要多一次的网络调用，但是内网的调用对于性能的损耗有限，却可以减少机器ID的位数，如果发号器以主备方式部署，同时运行的只有一个发号器，那么机器ID可以省略，这样可以留更多的位数给最后的自增信息位。即使需要机器ID，因为发号器部署实例数有限，那么就可以把机器ID写在发号器的配置文件里，这样可以保证机器ID唯一性，也无需引入第三方组件了。

局限：

> * 过于依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的ID。
> * 如果请求发号器的QPS不高，比如说发号器每毫秒只发一个ID，就会造成生成ID的末位永远是1，那么在分库分表时如果使用ID作为分区键就会造成库表分配的不均匀
>   * 时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均。
>   * 生成的序列号的起始号可以做一下随机，这一秒是21，下一秒是30，这样就会尽量地均衡了

# 7. NoSQL

**分类：**

> - Redis、LevelDB这样的KV存储。这类存储相比于传统的数据库的优势是极高的读写性能，一般对性能有比较高的要求的场景会使用。
> - Hbase、Cassandra这样的列式存储数据库。这种数据库的特点是数据不像传统数据库以行为单位来存储，而是以列来存储，适用于一些离线数据统计的场景。
> - 像MongoDB、CouchDB这样的文档型数据库。这种数据库的特点是Schema Free（模式自由），数据表中的字段可以任意扩展，比如说电商系统中的商品有非常多的字段，并且不同品类的商品的字段也都不尽相同，使用关系型数据库就需要不断增加字段支持，而用文档型数据库就简单很多了。

**特点：**

> 1.在性能方面，NoSQL数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；（**基于LSM树的存储引擎**）
>
> 2.在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要NoSQL数据库的支持；
>
> 3.在扩展性方面，NoSQL数据库天生支持分布式，支持数据冗余和数据分片的特性。

# 8. 缓存

## 8.1 缓存读写策略

### 8.1.1 旁路缓存技术

**读策略**

- 从缓存中读取数据；
- 如果缓存命中，则直接返回数据；
- 如果缓存不命中，则从数据库中查询数据；
- 查询到数据后，将数据写入到缓存中，并且返回给用户。

**写策略**

- 更新数据库中的记录；
- 删除缓存记录

> **不可以先删缓存再更新数据库 ，虽然先更新数据库再删缓存，在理论上也会出现数据不一致的情况，但因为缓存的写入远远快于数据库的写入，所以出现数据不一致的概率很低**



**缺陷：**

当写入比较多时，缓存中的数据会被频繁的清理，这样会对缓存的命中率有影响

> * 在更新数据库的同时也更新缓存，只是在更新缓存前加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，这样就不存在并发问题，只是对于写入的性能有影响
> * 另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。



### 8.1.2 读写穿透

**读策略**

- 从 cache 中读取数据，读取到就直接返回 。
- 读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

**写策略**

- 先查 cache，cache 中不存在，直接更新 DB。
- cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（**同步更新 cache 和 DB**）

> Read Through/Write Through策略的特点是由缓存节点而非用户来和数据库打交道，在我们开发过程中相比Cache Aside策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是Memcached还是Redis都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略
>



### 8.1.3 异步缓存写入



**只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB**

> 效率高，但使用的比较少，数据一致性要求比较低
>



## 8.2  数据分片

* 普通哈希取余算法

> 当增删节点时，这时取余将会完全打乱，导致所有数据都要迁移，造成缓存大面积失效

* 一致性哈希算法

> 当增删节点时，只需要迁移附近的一个节点就可以了



**一致性哈希算法的缺点**

> * 缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大；当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成压力。
> * 一致性Hash算法的脏数据问题。

> **为什么会产生脏数据呢？**比方说，在集群中有两个节点A和B，客户端初始写入一个Key为k，值为3的缓存数据到Cache A中。这时如果要更新k的值为4，但是缓存A恰好和客户端连接出现了问题，那这次写入请求会写入到Cache B中。接下来缓存A和客户端的连接恢复，当客户端要获取k的值时，就会获取到存在Cache A中的脏数据3，而不是Cache B中的4。
>
> **所以，在使用一致性Hash算法时一定要设置缓存的过期时间，**这样当发生漂移时，之前存储的脏数据可能已经过期，就可以减少存在脏数据的几率。

## 8.3 缓存穿透

如何防止缓存穿透？

* 回种空值
* 使用布隆过滤器



布隆过滤器的缺点？

* 它在判断元素是否在集合中时是有一定错误几率的，当布隆过滤器判断元素在集合中时，这个元素可能不在集合中。但是一旦布隆过滤器判断这个元素不在集合中时，它一定不在集合中。**这一点非常适合解决缓存穿透的问题**

  * 一般都是使用多个哈希函数来减少误判

* 不支持删除元素

  > **布隆过滤器不支持删除元素的缺陷也和Hash碰撞有关。**给你举一个例子，假如两个元素A和B都是集合中的元素，它们有相同的Hash值，它们就会映射到数组的同一个位置。这时我们删除了A，数组中对应位置的值也从1变成0，那么在判断B的时候发现值是0，也会判断B是不在集合中的元素，就会得到错误的结论。
  >
  > **那么我是怎么解决这个问题的呢？**我会让数组中不再只有0和1两个值，而是存储一个计数。比如如果A和B同时命中了一个数组的索引，那么这个位置的值就是2，如果A被删除了就把这个值从2改为1。这个方案中的数组不再存储bit位，而是存储数值，也就会增加空间的



总的来说，**回种空值和布隆过滤器**是解决缓存穿透问题的两种最主要的解决方案，但是它们也有各自的适用场景，并不能解决所有问题。比方说当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力，我们把这个场景叫做“dog-pile effect”（狗桩效应），

这是典型的缓存并发穿透的问题，**那么，我们如何来解决这个问题呢？**解决狗桩效应的思路是尽量地减少缓存穿透后的并发，方案也比较简单：

> * 在代码中控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回。
>
> * 通过在Memcached或者Redis中设置分布式锁，只有获取到锁的请求才能够穿透到数据库。



使用场景：

> * 回种空值是一种最常见的解决思路，实现起来也最简单，如果评估空值缓存占据的缓存空间可以接受，那么可以优先使用这种方案；
> * 布隆过滤器会引入一个新的组件，也会引入一些开发上的复杂度和运维上的成本。所以只有在存在海量查询数据库中，不存在数据的请求时才会使用，在使用时也要关注布隆过滤器对内存空间的消耗；
> * 对于极热点缓存数据穿透造成的“狗桩效应”，可以通过设置分布式锁或者后台线程定时加载的方式来解决。

# 9. CDN

* 使用分布式缓存对动态请求数据的读取做了加速
* 使用CDN对静态资源请求进行加速（**静态资源访问的关键点是就近访问**）



* **如何将用户的请求映射到CDN节点上？**

> DNS技术是CDN实现中使用的核心技术，可以将用户的请求映射到CDN节点上

* **如何根据用户的地理位置信息选择到比较近的节点？**

> GSLB（全局负载均衡）可以给用户返回一个离着他更近的节点，加快静态资源的访问速度
>
> * 可以将用户的IP地址按照地理位置划分为若干个区域，然后将CDN节点对应到一个区域上，根据用户所在区域来返回合适的节点；
> * 也可以通过发送数据包测量RTT的方式来决定返回哪一个节点

# 10 数据迁移

- 迁移应该是在线的迁移，也就是在迁移的同时还会有数据的写入；
- 数据应该保证完整性，也就是说在迁移之后需要保证新的库和旧的库的数据是一致的；
- 迁移的过程需要做到可以回滚，这样一旦迁移的过程中出现问题，可以立刻回滚到源库不会对系统的可用性造成影响。

## 10.1 双写方案

1. 将新的库配置为源库的从库用来同步数据；如果需要将数据同步到多库多表，那么可以使用一些第三方工具获取Binlog的增量日志（比如开源工具Canal），在获取增量日志之后就可以按照分库分表的逻辑写入到新的库表中了。
2. 同时我们需要改造业务代码，在数据写入的时候不仅要写入旧库也要写入新库。当然，基于性能的考虑，我们可以异步地写入新库，只要保证旧库写入成功即可。**但是我们需要注意的是，**需要将写入新库失败的数据记录在单独的日志中，这样方便后续对这些数据补写，保证新库和旧库的数据一致性。
3. 然后我们就可以开始校验数据了。由于数据库中数据量很大，做全量的数据校验不太现实。你可以抽取部分数据，具体数据量依据总体数据量而定，只要保证这些数据是一致的就可以。
4. 如果一切顺利，我们就可以将读流量切换到新库了。由于担心一次切换全量读流量可能会对系统产生未知的影响，所以这里**最好采用灰度的方式来切换，**比如开始切换10%的流量，如果没有问题再切换到50%的流量，最后再切换到100%。
5. 由于有双写的存在，所以在切换的过程中出现任何的问题都可以将读写流量随时切换到旧库去，保障系统的性能。
6. 在观察了几天发现数据的迁移没有问题之后，就可以将数据库的双写改造成只写新库，数据的迁移也就完成了。

> 1. 旧库：读写；  新库：无
> 2. 旧库：读写；  新库：写
> 3. 旧库：写；     新库：读写
> 4. 旧库：无；     新库：读写

* 优点：迁移的过程可以随时回滚，将迁移的风险降到了最低。

* 缺点：时间周期比较长，应用有改造的成本

## 10.2 级联同步方案

这种方案也比较简单，比较适合数据从**自建机房向云上迁移**的场景。因为迁移上云最担心云上的环境和自建机房的环境不一致，会导致数据库在云上运行时因为参数配置或者硬件环境不同出现问题。

所以我们**会在自建机房准备一个备库**，在云上环境上准备一个新库，通过级联同步的方式在自建机房留下一个可回滚的数据库

> 1. 先将新库配置为旧库的从库，用作数据同步；
> 2. 再将一个备库配置为新库的从库，用作数据的备份；
> 3. 等到三个库的写入一致后，将数据库的读流量切换到新库；
> 4. 然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。



数据同步方式： 旧库 -> 新库 -> 备库

> 1. 旧库：读写；  新库：无；     备库：无    旧库 -> 新库 -> 备库
> 2. 旧库：写；     新库：读。     备库： 无       旧库 -> 新库 -> 备库
> 3. 旧库：无；     新库：读写；  备库：无        旧库 -> 新库 -> 备库
> 4. 旧库：无；     新库：读写；  备库： 无       新库 -> 备库



**这种方案的回滚方案也比较简单，**可以先将读流量切换到备库再暂停应用的写入，将写流量切换到备库，这样所有的流量都切换到了备库，也就是又回到了自建机房的环境，就可以认为已经回滚了。



## 10.3 预热缓存

1. 在云上部署多组缓存的副本组，自建机房在接收到写入请求时，会优先写入自建机房的缓存节点，异步写入云上部署的缓存节点；
2. 在处理自建机房的读请求时，会指定一定的流量（比如10%）优先走云上的缓存节点，这样虽然也会走专线穿透回自建机房的缓存节点，但是流量是可控的；
3. 当云上缓存节点的命中率达到90%以上时，就可以在云上部署应用服务器，让云上的应用服务器完全走云上的缓存节点就可以了。

# 11. 消息队列

**幂等不能解决的问题：**如果消息在处理之后，还没有来得及写入数据库，消费者宕机了重启之后发现数据库中并没有这条消息，还是会重复执行两次消费逻辑，这时你就需要引入事务机制，保证消息处理和写入数据库必须同时成功或者同时失败，但是这样消息处理的成本就更高了，所以如果对于消息重复没有特别严格的要求，可以直接使用这种通用的方案，而不考虑引入事务。



**如何在业务层面处理重复消费问题？**这里有很多种处理方式，其中有一种是增加乐观锁的方式。比如你的消息处理程序需要给一个人的账号加钱，那么你可以通过乐观锁的方式来解决。

**具体的操作方式是这样的：**你给每个人的账号数据中增加一个版本号的字段，在生产消息时先查询这个账户的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新账户金额SQL的时候带上版本号，类似于执行：

```sql
update user set amount = amount + 20, version=version+1 where userId=1 and version=1;
```



**如何减少消息延迟？**

* 优化消费代码提升性能
* 增加消费者数量

> 不过第二种方式会受限于消息队列的实现。如果消息队列使用的是Kafka就无法通过增加消费者数量的方式来提升消息处理能力，但**可以再增加一些分区**
>
> Kafka约定一个分区只能被一个消费者消费，为什么要这么设计呢？在我看来，如果有多个consumer（消费者）可以消费一个分区的数据，那么在操作这个消费进度的时候就需要加锁，可能会对性能有一定的影响。



**如何在不增加分区的前提下提升消费能力？**

> 在消费者处用线程池处理

# 12. 微服务化系统架构

**一体化系统的局限性**

> - 系统中使用的资源出现扩展性问题，尤其是数据库的连接数出现瓶颈；
> - 大团队共同维护一套代码，带来研发效率的降低和研发成本的提升；
> - 系统部署成本越来越高。



**微服务拆分的原则：**

> * 做到单一服务内部功能的高内聚和低耦合
> * 服务拆分先粗粒度再逐渐细化
> * 拆分的过程中，要尽量避免影响产品的日常功能迭代（一边做产品功能迭代，一边完成服务化拆分）
> * 服务接口的定义要具备可扩展性



**微服务带来的问题：**

> * 服务接口的调用不再是同一进程内的方法调用，而是跨进程的网络调用，这会增加接口响应时间
> * 多个服务之间有着错综复杂的依赖关系，一旦被依赖的服务的性能出现问题产生大量的慢请求，就会导致依赖服务的工作线程池中的线程被打满，依赖的服务也会出现性能问题，层层蔓延，直到整个系统出现故障（**需要采用熔断、降级、限流、超时控制的方法，使问题被限制在单一服务中**）
> * 服务拆分后，一条请求的调用链路涉及多个服务，那么一旦这个请求的响应时间增长或者出现错误，我们就很难知道是哪一个服务出现的问题（**需要引入分布式追踪工具，以及更细致的服务端监控报表**）



# 13. RPC框架

如何提升RPC框架的性能？

* 提升网络传输性能
* 选择合适的序列化方式



在网络传输优化中，你首先要做的是选择一种高性能的I/O模型。所谓I/O模型，就是我们处理I/O的方式。而一般单次I/O请求会分为两个阶段，每个阶段对于I/O的处理方式是不同的。

**首先，I/O会经历一个等待资源的阶段，**比方说，等待网络传输数据可用，在这个过程中我们对I/O会有两种处理方式：

- 阻塞。指的是在数据不可用时I/O请求一直阻塞，直到数据返回；
- 非阻塞。指的是数据不可用时I/O请求立即返回，直到被通知资源可用为止。

**然后是使用资源的阶段，**比如说从网络上接收到数据，并且拷贝到应用程序的缓冲区里面。在这个阶段我们也会有两种处理方式：

- 同步处理。指的是I/O请求在读取或者写入数据时会阻塞，直到读取或者写入数据完成；
- 异步处理。指的是I/O请求在读取或者写入数据时立即返回，当操作系统处理完成I/O请求并且将数据拷贝到用户提供的缓冲区后，再通知应用I/O请求执行完成。



# 14. 服务注册中心

**解决分布式系统寻址的问题**



> - 注册中心可以让我们动态地变更RPC服务的节点信息，对于动态扩缩容，故障快速恢复，以及服务的优雅关闭都有重要的意义；
> - 心跳机制是一种常见的探测服务状态的方式，你在实际的项目中也可以考虑使用；
> - 我们需要对注册中心中管理的节点提供一些保护策略，避免节点被过度摘除导致的服务不可用

# 15. 分布式trace

**排查横跨几十个分布式组件的慢请求**



**一体化架构中的慢请求排查**

为防止同时会有多个下单请求并行处理导致下单请求的每个步骤的耗时日志事相互穿插打印的，这样就无法知道这些日志哪些是来自同一个请求。

解决方法：

给同一个请求的每一行日志增加一个相同的标记（requestId）

```java
String requestId = UUID.randomUUID().toString();
ThreadLocal tl = new ThreadLocal(){
    @Override
    protected String initialValue() {
        return requestId;
    }
}; //requestId存储在线程上下文中
long start = System.currentTimeMillis();
processA();
Logs.info("rid : " + tl.get() + ", process A cost " + (System.currentTimeMillis() - start)); // 日志中增加requestId
start = System.currentTimeMillis();
processB();
Logs.info("rid : " + tl.get() + ", process B cost " + (System.currentTimeMillis() - start));
start = System.currentTimeMillis();
processC();
Logs.info("rid : " + tl.get() + ", process C cost " + (System.currentTimeMillis() - start));
```



我们使用**静态代理**的方式做**切面编程**，避免在业务代码中，加入大量打印耗时的日志的代码，减少了对于代码的侵入性，同时编译期的代码注入可以减少

> - 一类是静态代理，典型的代表是AspectJ，它的特点是在编译期做切面代码注入；
> - 另一类是动态代理，典型的代表是Spring AOP，它的特点是在运行期做切面代码注入。
>
> **这两者有什么差别呢？**以Java为例，源代码Java文件先被Java编译器编译成Class文件，然后Java虚拟机将Class装载进来之后，进行必要的验证和初始化后就可以运行了。
>
> 静态代理是在编译期插入代码，增加了编译的时间，给你的直观感觉就是启动的时间变长了，但是一旦在编译期插入代码完毕之后在运行期就基本对于性能没有影响。
>
> 而动态代理不会去修改生成的Class文件，而是会在运行期生成一个代理对象，这个代理对象对源对象做了字节码增强，来完成切面所要执行的操作。由于在运行期需要生成代理对象，所以动态代理的性能要比静态代理要差。

```java
@Aspect
public class Tracer {
    @Around(value = "execution(public methodsig)", argNames = "pjp") //execution内替换要做切面的方法签名
    public Object trace(ProceedingJoinPoint pjp) throws Throwable {
        TraceContext traceCtx = TraceContext.get(); //获取追踪上下文，上下文的初始化可以在程序入口处
        String requestId = reqCtx.getRequestId(); //获取requestId
        String sig = pjp.getSignature().toShortString(); //获取方法签名
        boolean isSuccessful = false;
        String errorMsg = "";
        Object result = null;
        long start = System.currentTimeMillis();
        try {
            result = pjp.proceed();
            isSuccessful = true;
            return result;
        } catch (Throwable t) {
            isSuccessful = false;
            errorMsg = t.getMessage();
            return result;
        } finally {
            long elapseTime = System.currentTimeMillis() - start;
            Logs.info("rid : " + requestId + ", start time: " + start + ", elapseTime: " + elapseTime + ", sig: " + sig + ", isSuccessful: " + isSuccessful + ", errorMsg: " + errorMsg  );
        }
    }

}
```



Q：为了减少磁盘IO的负载，如何减少日志的数量？

A：可以考虑对请求进行采样，比如想采样10%的日志，可以 requestId % 10 == 0的请求

Q：有了这些日志之后，当给你一个requestId的时候，你发现自己并不能确定这个请求到了哪一台服务器上，所以你不得不登录所有的服务器去搜索这个requestId才能定位请求。**这样无疑会增加问题排查的时间**

A：把日志不打印到本地文件中，而是发送到消息队列里，再由消息处理程序写入到集中存储中，比如Elasticsearch。这样，你在排查问题的时候，只需要拿着requestId到Elasticsearch中查找相关的记录就好了



**如何来做分布式Trace**

你也可以通过requestId将多个服务器上的日志串起来，但是仅仅依靠requestId很难表达清楚服务之间的调用关系，所以从日志中就无法了解服务之间是谁在调用谁。因此，我们采用traceId + spanId这两个数据维度来记录服务之间的调用关系（这里traceId就是requestId），也就是使用traceId串起单次请求，用spanId记录每一次RPC调用。

> - 用户到A服务之后会初始化一个traceId为100，spanId为1；
> - A服务调用B服务时，traceId不变，而spanId用1.1标识代表上一级的spanId是1，这一级的调用次序是1；
> - A调用C服务时，traceId依然不变，spanId则变为了1.2，代表上一级的spanId还是1，而调用次序则变成了2，以此类推。

**那么spanId是何时生成的，又是如何传递的呢？**这部分内容可以算作一个延伸点，能够帮你了解分布式Trace中间件的实现原理。

> 首先，A服务在发起RPC请求服务B前，先从线程上下文中获取当前的traceId和spanId，然后依据上面的逻辑生成本次RPC调用的spanId，再将spanId和traceId序列化后装配到请求体中，发送给服务方B。
>
> 服务方B获取请求后，从请求体中反序列化出spanId和traceId，同时设置到线程上下文中，以便给下次RPC调用使用。在服务B调用完成返回响应前，计算出服务B的执行时间发送给消息队列。
>
> 当然，在服务B中，你依然可以使用切面编程的方式，得到所有调用的数据库、缓存、HTTP服务的响应时间，只是在发送给消息队列的时候，要加上当前线程上下文中的spanId和traceId。

# 16.负载均衡

**负载均衡服务是提升系统扩展性和性能的重要组件**



- 网站负载均衡服务的部署，是以LVS承接入口流量，在应用服务器之前，部署Nginx做细化的流量分发和故障节点检测。当然，如果你的网站的并发不高，也可以考虑不引入LVS。
- 负载均衡的策略可以优先选择动态策略，保证请求发送到性能最优的节点上；如果没有合适的动态策略，那么可以选择轮询的策略，让请求平均分配到所有的服务节点上。
- Nginx可以引入nginx_upstream_check_module，对后端服务做定期的存活检测，后端的服务节点在重启时，也要秉承着“先切流量后重启”的原则，尽量减少节点重启对于整体系统的影响。

# 17. API网关

1. API网关分为入口网关和出口网关两类，入口网关作用很多，可以隔离客户端和微服务，从中提供协议转换、安全策略、认证、限流、熔断等功能。出口网关主要是为调用第三方服务提供统一的出口，在其中可以对调用外部的API做统一的认证、授权、审计以及访问控制；
2. API网关的实现重点在于性能和扩展性，你可以使用多路I/O复用模型和线程池并发处理，来提升网关性能，使用责任链模式来提升网关的扩展性；
3. API网关中的线程池可以针对不同的接口或者服务做隔离和保护，这样可以提升网关的可用性；
4. API网关可以替代原本系统中的Web层，将Web层中的协议转换、认证、限流等功能挪入到API网关中，将服务聚合的逻辑下沉到服务层。

# 18. 多机房部署

- 不同机房的数据传输延迟是造成多机房部署困难的主要原因，你需要知道，同城多机房的延迟一般在1ms~3ms，异地机房的延迟在50ms以下，而跨国机房的延迟在200ms以下。
- **同城多机房方案**可以允许有跨机房数据写入的发生，但是数据的读取和服务的调用应该尽量保证在同一个机房中。

> 因为绝大多数业务都是读多写少，所以可以允许有跨机房数据写入的发生，但读的次数太多，一般读要尽量保证在同一个机房中，实现方式：在一个机房有一个主库和从库，其他机房都只有一个从库，这样都写在主库上，读都是从各机房的从库上读，，一旦主库所在的机房出现故障，那就把其他机房的从库升级为主库

- **异地多活方案**则应该避免跨机房同步的数据写入和读取，而是采取异步的方式，将数据从一个机房同步到另一个机房。

> 所以，在数据写入时，你要保证只写本机房的数据存储服务再采取数据同步的方案，将数据同步到异地机房中。**一般来说，数据同步的方案有两种：**
>
> - 一种基于存储系统的主从复制，比如MySQL和Redis。也就是在一个机房部署主库，在异地机房部署从库，两者同步主从复制实现数据的同步。
> - 另一种是基于消息队列的方式。一个机房产生写入请求后，会写一条消息到消息队列，另一个机房的应用消费这条消息后再执行业务处理逻辑，写入到存储服务中。
>
> **我建议你**采用两种同步相结合的方式，比如，你可以基于消息的方式，同步缓存的数据、HBase数据等。然后基于存储，主从复制同步MySQL、Redis等数据。
>
> 无论是采取哪种方案，数据从一个机房传输到另一个机房都会有延迟，所以，你需要尽量保证用户在读取自己的数据时，读取数据主库所在的机房。为了达到这一点，你需要对用户做分片，让一个用户每次的读写都尽量在同一个机房中。同时，在数据读取和服务调用时，也要尽量调用本机房的服务。**这里有一个场景：**假如在电商系统中，用户A要查看所有订单的信息，而这些订单中，店铺的信息和卖家的信息很可能是存储在异地机房中，那么你应该优先保证服务调用，和数据读取在本机房中进行，即使读取的是跨机房从库的数据，会有一些延迟，也是可以接受的。

# 19. 服务端监控

谷歌针对分布式系统监控的经验总结，四个黄金信号（Four Golden Signals）。它指的是在服务层面一般需要监控四个指标，**分别是延迟、通信量、错误和饱和度。**

- 延迟指的是请求的响应时间。比如接口的响应时间、访问数据库和缓存的响应时间。
- 通信量可以理解为吞吐量，也就是单位时间内请求量的大小。比如访问第三方服务的请求量，访问消息队列的请求量。
- 错误表示当前系统发生的错误数量。**这里需要注意的是，** 我们需要监控的错误既有显式的，比如在监控Web服务时，出现4 * *和 5 * *的响应码；也有隐式的，比如Web服务虽然返回的响应码是200，但是却发生了一些和业务相关的错误（出现了数组越界的异常或者空指针异常等），这些都是错误的范畴。
- 饱和度指的是服务或者资源到达上限的程度（也可以说是服务或者资源的利用率），比如CPU的使用率、内存使用率、磁盘使用率、缓存数据库的连接数等等。



**Agent、埋点和日志是三种最常见的数据采集方式**



**访问趋势报表用来展示服务的整体运行情况，性能报表用来分析资源或者依赖的服务是否出现问题，资源报表用来追查资源问题的根本原因。这三个报表共同构成了你的服务端监控体系。**

**1. 访问趋势报表。**这类报表接入的是Web服务器，和应用服务器的访问日志，展示了服务整体的访问量、响应时间情况、错误数量、带宽等信息。它主要反映的是服务的整体运行情况，帮助你来发现问题。

**2. 性能报表。** 这类报表对接的是资源和依赖服务的埋点数据，展示了被埋点资源的访问量和响应时间情况。它反映了资源的整体运行情况，当你从访问趋势报表发现问题后，可以先从性能报表中，找到究竟是哪一个资源或者服务出现了问题。

**3. 资源报表。** 这类报表主要对接的是，使用Agent采集的资源的运行情况数据。当你从性能报表中，发现某一个资源出现了问题，那么就可以进一步从这个报表中，发现资源究竟出现了什么问题，是连接数异常增高还是缓存命中率下降。这样可以进一步帮你分析问题的根源，找到解决问题的方案。

# 20. 应用性能管理APM

1.从客户端采集到的数据可以用通用的消息格式，上传到APM服务端，服务端将数据存入到Elasticsearch中，以提供原始日志的查询，也可以依据这些数据形成客户端的监控报表；

2.用户网络数据是我们排查客户端，和服务端交互过程的重要数据，你可以通过代码的植入，来获取到这些数据；

3.无论是网络数据，还是异常数据，亦或是卡顿、崩溃、流量、耗电量等数据，你都可以通过把它们封装成APM消息格式，上传到APM服务端，这些用户在客户端上留下的踪迹可以帮助你更好地优化用户的使用体验。

# 21. 压测

**压测需要注意的点：**

> * 做压力测试时，最好使用线上的数据和线上的环境。因为，你无法确定自己搭建的测试环境与正式环境的差异，是否会影响到压力测试的结果。
> * 压力测试时不能使用模拟的请求而是要使用线上的流量。你可以通过拷贝流量的方式，把线上流量拷贝一份到压力测试环境。因为模拟流量的访问模型和线上流量相差很大，会对压力测试的结果产生比较大的影响。
>   * 比如，你在获取商品信息的时候，线上的流量会获取不同商品的数据，这些商品的数据有的命中了缓存，有的没有命中缓存。如果使用同一个商品ID来做压力测试，那么只有第一次请求没有命中缓存，而在请求之后会将数据库中的数据回种到缓存，后续的请求就一定会命中缓存了，这种压力测试的数据就不具备参考性了。
> * 不要从一台服务器发起流量，这样很容易达到这台服务器性能瓶颈，从而导致压力测试的QPS上不去，最终影响压力测试的结果



**全链路压测平台包含的模块：**

- 流量构造和产生模块；
- 压测数据隔离模块；
- 系统健康度检查和压测流量干预模块。

# 22. 配置中心

**管理配置的方式：**

* 通过配置文件来管理（需要将服务重启才能使配置生效）
* 使用配置中心来管理



**配置中心如何实现：**

* 配置信息如何存储（mysql，redis，zk都可以）
* 变更推送如何实现（轮询查询（常用）；长连推送）



**变更推送如何实现**

> 轮询查询很简单，就是应用程序向配置中心客户端注册一个监听器，配置中心的客户端，定期地（比如1分钟）查询所需要的配置是否有变化，如果有变化则通知触发监听器，让应用程序得到变更通知。
>
> **这里有一个需要注意的点，**如果有很多应用服务器都去轮询拉取配置，由于返回的配置项可能会很大，那么配置中心服务的带宽就会成为瓶颈。为了解决这个问题，我们会给配置中心的每一个配置项多存储一个根据配置项计算出来的MD5值。
>
> 配置项一旦变化，这个MD5值也会随之改变。配置中心客户端在获取到配置的同时，也会获取到配置的MD5值，并且存储起来。那么在轮询查询的时候，需要先确认存储的MD5值和配置中心的MD5是不是一致的。如果不一致，这就说明配置中心里存储的配置项有变化，然后才会从配置中心拉取最新的配置。
>
> 由于配置中心里存储的配置项变化的几率不大，所以使用这种方式后，每次轮询请求就只是返回一个MD5值，可以大大地减少配置中心服务器的带宽。

![e846f4c4418f8ca137a1fd2dcbbb3b7f](https://static001.geekbang.org/resource/image/e8/7f/e846f4c4418f8ca137a1fd2dcbbb3b7f.jpg)

> 另一种长连的方式，它的逻辑是在配置中心服务端保存每个连接关注的配置项列表。这样当配置中心感知到配置变化后，就可以通过这个连接把变更的配置推送给客户端。这种方式需要保持长连，也需要保存连接和配置的对应关系，实现上要比轮询的方式复杂一些，但是相比轮询方式来说，能够更加实时地获取配置变更的消息。



**如何保证配置中心高可用**

> 我们一般会在配置中心的客户端上，增加两级缓存：第一级缓存是内存的缓存；另外一级缓存是文件的缓存。
>
> 配置中心客户端在获取到配置信息后，会同时把配置信息同步地写入到内存缓存，并且异步地写入到文件缓存中。内存缓存的作用是降低客户端和配置中心的交互频率，提升配置获取的性能；而文件的缓存的作用就是灾备，当应用程序重启时，一旦配置中心发生故障，那么应用程序就会优先使用文件中的配置，这样虽然无法得到配置的变更消息（因为配置中心已经宕机了），但是应用程序还是可以启动起来的，算是一种降级的方案。

# 23. 熔断降级

在分布式环境下，系统最怕的反而不是某一个服务或者组件宕机，而是最怕它响应缓慢，因为，某一个服务或者组件宕机也许只会影响系统的部分功能，但它响应一慢，就会出现雪崩拖垮整个系统。

在检测到某一个服务的响应时间出现异常时，切断调用它的服务与它之间的联系，让服务的调用快速返回失败，从而释放这次请求持有的资源。**这个思路也就是我们经常提到的降级和熔断机制。**



**熔断机制是如何做的？**

服务治理中的熔断机制指的是在发起服务调用的时候，如果返回错误或者超时的次数超过一定阈值，则后续的请求不再发向远程服务而是暂时返回错误。这种实现方式在云计算领域又称为断路器模式，在这种模式下，服务调用方为每一个调用的服务维护一个有限状态机，在这个状态机中会有三种状态：关闭（调用远程服务）、半打开（尝试调用远程服务）和打开（返回错误）。这三种状态之间切换的过程是下面这个样子。

- 当调用失败的次数累积到一定的阈值时，熔断状态从关闭态切换到打开态。一般在实现时，如果调用成功一次，就会重置调用失败次数。
- 当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时后，状态切换到半打开态。你也可以通过设置一个定时器，定期地探测服务是否恢复。
- 在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定的成功次数后，状态切换到关闭态；如果出现调用失败的情况，则切换到打开态。

![9fc3934e1e0923fe990e0bdbe3aec787](https://static001.geekbang.org/resource/image/9f/87/9fc3934e1e0923fe990e0bdbe3aec787.jpg)

**开关降级如何做**

开关降级指的是在代码中预先埋设一些“开关”，用来控制服务调用的返回值。比方说，开关关闭的时候正常调用远程服务，开关打开时则执行降级的策略。这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要通过配置中心动态更改开关的值，就可以实现不重启服务快速地降级远程服务了。

> - 针对读取数据的场景，我们一般采用的策略是直接返回降级数据。比如，如果数据库的压力比较大，我们在降级的时候，可以考虑只读取缓存的数据，而不再读取数据库中的数据；如果非核心接口出现问题，可以直接返回服务繁忙或者返回固定的降级数据。
> - 对于一些轮询查询数据的场景，比如每隔30秒轮询获取未读数，可以降低获取数据的频率（将获取频率下降到10分钟一次）。
> - 而对于写数据的场景，一般会考虑把同步写转换成异步写，这样可以牺牲一些数据一致性保证系统的可用性。

# 24. 限流

限流算法

* 固定窗口
* 滑动窗口
* 漏桶

> 它就像在流量产生端和接收端之间增加一个漏桶，流量会进入和暂存到漏桶里面，而漏桶的出口处会按照一个固定的速率将流量漏出到接收端（也就是服务接口）。
>
> 如果流入的流量在某一段时间内大增，超过了漏桶的承受极限，那么多余的流量就会触发限流策略，被拒绝服务。

* 令牌桶

> - 如果我们需要在一秒内限制访问次数为N次，那么就每隔1/N的时间，往桶内放入一个令牌；
> - 在处理请求之前先要从桶中获得一个令牌，如果桶中已经没有了令牌，那么就需要等待新的令牌或者直接拒绝服务；
> - 桶中的令牌总数也要有一个限制，如果超过了限制就不能向桶中再增加新的令牌了。这样可以限制令牌的总数，一定程度上可以避免瞬时流量高峰的问题。



**固定窗口的缺陷：**

> 无法限制短时间之内的集中流量。假如我们需要限制每秒钟只能处理10次请求，如果前一秒钟产生了10次请求，这10次请求全部集中在最后的10毫秒中，而下一秒钟的前10毫秒也产生了10次请求，那么在这20毫秒中就产生了20次请求，超过了限流的阈值。但是因为这20次请求分布在两个时间窗口内，所以没有触发限流，这就造成了限流的策略并没有生效。

**滑动窗口的缺陷：**

> 滑动窗口的算法解决了临界时间点上突发流量无法控制的问题，但是却因为要存储每个小的时间窗口内的计数，所以空间复杂度有所增加。
>
> 虽然滑动窗口算法解决了窗口边界的大流量的问题，但是它和固定窗口算法一样，还是无法限制短时间之内的集中流量，也就是说无法控制流量让它们更加平滑。

**漏桶算法的缺陷：**

> **漏桶算法在面对突发流量的时候，采用的解决方式是缓存在漏桶中，** 这样流量的响应时间就会增长，这就与互联网业务低延迟的要求不符（因为如果有令牌，这样就可以让流量快速过去，而不用等待固定速率）











